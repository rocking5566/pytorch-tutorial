{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64c49d6",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "* Tensorboard 可以用來看 learning curve, 模型視覺化, 權重跟特徵的分佈...etc\n",
    "* tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a68253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from mnist import ConvNet\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fe196",
   "metadata": {},
   "source": [
    "# Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46529dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = ConvNet(num_classes)\n",
    "model.eval()\n",
    "\n",
    "x = Image.open('mnist_2.jpg', mode='r')\n",
    "x_th = torchvision.transforms.ToTensor()(x).reshape(1, 1, 28, 28)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist')\n",
    "writer.add_graph(model, x_th)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa729f",
   "metadata": {},
   "source": [
    "# Learning curve\n",
    "* 一般會將少量的 training data 切成 training set 跟 validation set\n",
    "* 我們會在 training set 上跑梯度下降, 然後看 training loss 有沒有正常下降\n",
    "* 為了防止 overfitting, 要比較 training loss 跟 validation loss 是否接近, 印數字或畫 learning curve 都可以\n",
    "* 除了對 loss, 也可以對標 training set 跟 validation set 的精度\n",
    "* 一般打比賽的 test set 沒有公開 label, 所以建模不會用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mnist')\n",
    "\n",
    "# Fake gradient descent\n",
    "data_count = 1000\n",
    "train_loss = 0\n",
    "for epoch in range(2):\n",
    "    for t in range(data_count):\n",
    "        iter = (epoch * data_count) + t\n",
    "        train_loss += data_count / (iter + 1)\n",
    "\n",
    "        if (t + 1) % 100 == 0:\n",
    "            train_loss = train_loss / 100\n",
    "            #  Evaluate val_loss on entire validation_set\n",
    "            val_loss = train_loss + random.uniform(-train_loss * 0.2, train_loss * 0.2)\n",
    "\n",
    "            print(f'iter = {iter}, train_loss = {train_loss}, val_loss = {val_loss}')\n",
    "            writer.add_scalar('training loss', train_loss, iter)\n",
    "            writer.add_scalar('validation loss', val_loss, iter)\n",
    "            train_loss = 0\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
